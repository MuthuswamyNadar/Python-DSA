{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf70f42d",
   "metadata": {},
   "source": [
    "# 1. What is ensemble learning in machine learning?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e23bc",
   "metadata": {},
   "source": [
    "Ensemble learning is a technique that combines multiple individual models (often referred to as \"learners\") to produce a more accurate and robust overall model. By aggregating predictions from multiple models, ensemble methods can improve predictive performance and reduce the risk of overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41247c8f",
   "metadata": {},
   "source": [
    "# 2. Explain the key idea behind ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848ecc0",
   "metadata": {},
   "source": [
    "The key idea behind ensemble techniques is that a group of weak learners can be combined to create a strong learner. The diversity among the models can help compensate for individual model errors, reducing variance and improving accuracy. Ensemble methods leverage the principle of 'wisdom of the crowd'—collective predictions yield better results than predictions from individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86d7c3",
   "metadata": {},
   "source": [
    "# 3. What are the main types of ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881975fd",
   "metadata": {},
   "source": [
    "The main types of ensemble techniques are:\n",
    "\n",
    "Bagging (Bootstrap Aggregating): Reduces variance by training multiple models on different random subsets of the data and averaging their predictions (for regression) or taking a majority vote (for classification).\n",
    "\n",
    "Boosting: Sequentially applies weak learners, adjusting weights so that subsequent models focus more on the mistakes of earlier ones. It combines models to improve performance iteratively.\n",
    "\n",
    "Stacking: Combines multiple models via a meta-learner that learns how to best combine the predictions of the base models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7204999",
   "metadata": {},
   "source": [
    "# 4. What is the main advantage of ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac6c4bd",
   "metadata": {},
   "source": [
    "The main advantage of ensemble techniques is improved prediction accuracy and robustness. By utilizing the strengths of multiple models, ensemble methods can achieve better performance than any individual model, reducing overfitting and increasing generalization to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670df29d",
   "metadata": {},
   "source": [
    "# 5. What is the main challenge of ensemble methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed53cf1",
   "metadata": {},
   "source": [
    "The main challenge of ensemble methods is increased computational complexity. Training multiple models can be resource-intensive in terms of time and memory usage. Ensemble methods can also lead to difficulties in model interpretability, as it may be harder to understand how different models contribute to the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e86fc",
   "metadata": {},
   "source": [
    "# 6. When should we avoid using ensemble methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183fd6e",
   "metadata": {},
   "source": [
    "We should avoid using ensemble methods when:\n",
    "\n",
    "The dataset is very small, as the complexity of ensembles may not be justified.\n",
    "\n",
    "Interpretability is crucial, and simpler, more interpretable models can provide sufficient accuracy.\n",
    "\n",
    "Computational resources are severely limited, as training multiple models can be demanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d1fad",
   "metadata": {},
   "source": [
    "# 7. Can we use Bagging for regression problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b222164",
   "metadata": {},
   "source": [
    "Yes, Bagging can be used for regression problems. In regression tasks, it works by averaging the predictions of multiple models trained on different bootstrapped samples of the dataset to reduce variance and improve accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb61fd33",
   "metadata": {},
   "source": [
    "# 8. Explain the working principle of a Bagging Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f3693",
   "metadata": {},
   "source": [
    "A Bagging Classifier works through the following steps:\n",
    "\n",
    "Multiple bootstrapped subsets of the training data are created (sampling with replacement).\n",
    "\n",
    "A base model (e.g., decision tree) is trained independently on each subset.\n",
    "\n",
    "For classification, predictions from each model are combined through majority voting to produce the final class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858abdda",
   "metadata": {},
   "source": [
    "# 9. How does a Bagging Regressor work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d29589",
   "metadata": {},
   "source": [
    "A Bagging Regressor follows a similar process to the Bagging Classifier, but predictions from the individual regressors are averaged instead of voting. \n",
    "\n",
    "Here’s the general workflow:\n",
    "\n",
    "Create multiple bootstrapped subsets from the training data.\n",
    "\n",
    "Train a base regress model (e.g., decision tree) on each subset.\n",
    "\n",
    "Combine the predictions by averaging the results to obtain the final predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3fc57",
   "metadata": {},
   "source": [
    "# 10. How does Bagging help in reducing overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166fd625",
   "metadata": {},
   "source": [
    "Bagging helps reduce overfitting by training models on various subsets of the data. This leads to a decrease in variance since different training sets emphasize different aspects of the data. By averaging the predictions of several models, Bagging smooths out individual model errors, which helps in generalizing better to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff27ab",
   "metadata": {},
   "source": [
    "# 11. What is the role of bootstrap sampling in Bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb11c3c",
   "metadata": {},
   "source": [
    "Bootstrap sampling is crucial in Bagging as it allows the creation of multiple diverse training subsets from the original dataset. Each subset is formed by sampling data points with replacement. This introduces variability among the models trained on these different subsets, which contributes to reducing overfitting and improving the overall ensemble performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a3204",
   "metadata": {},
   "source": [
    "# 12. How do you evaluate a Bagging Classifier’s performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b398151c",
   "metadata": {},
   "source": [
    "The performance of a Bagging Classifier can be evaluated using various metrics depending on the nature of the classification task. \n",
    "\n",
    "Common methods include:\n",
    "\n",
    "Accuracy: Proportion of correct predictions.\n",
    "\n",
    "Precision, Recall, F1-score: Suitable for imbalanced datasets.\n",
    "\n",
    "Confusion Matrix: Provides a detailed breakdown of true positives, false positives, etc.\n",
    "\n",
    "ROC-AUC Score: Measures the trade-off between true positive rate and false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6ccd0",
   "metadata": {},
   "source": [
    "# 13. What is a Random Forest Classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4310e",
   "metadata": {},
   "source": [
    "A Random Forest Classifier is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of their predictions for classification tasks. It combines the ideas of Bagging and random feature selection to ensure diverse trees and enhance predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38e05ca",
   "metadata": {},
   "source": [
    "# 14. Explain the concept of feature randomness in Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f2e9d",
   "metadata": {},
   "source": [
    "Feature randomness in Random Forest refers to the practice of selecting a random subset of features to consider when splitting a node in a decision tree. \n",
    "\n",
    "This randomness ensures that the trees are diverse, reducing correlation between them and leading to better generalization and robustness in predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940653ed",
   "metadata": {},
   "source": [
    "# 15. How can you measure the importance of features in a Random Forest model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ddb8c1",
   "metadata": {},
   "source": [
    "Feature importance in a Random Forest model can be measured using:\n",
    "\n",
    "Mean Decrease Impurity (MDI): Sums up the decrease in node impurity (e.g., Gini impurity) caused by a feature across all trees.\n",
    "\n",
    "Mean Decrease Accuracy (MDA): Evaluates feature importance by measuring how much the accuracy decreases when the feature's values are permuted (i.e., shuffled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f584a2d1",
   "metadata": {},
   "source": [
    "# 16. What is OOB (Out-of-Bag) Score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1df4d",
   "metadata": {},
   "source": [
    "The Out-of-Bag (OOB) Score is an internal validation method used in Random Forests.\n",
    "\n",
    " It calculates the performance of the model using data points that were not included in the bootstrap samples for a given tree. \n",
    "\n",
    "For each data point, its OOB prediction is made using trees that did not train on it. \n",
    "\n",
    "The average of these predictions gives an unbiased estimate of the model’s accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944f7e0c",
   "metadata": {},
   "source": [
    "# 17. Why is Random Forest better than a single Decision Tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ab744",
   "metadata": {},
   "source": [
    "Random Forest is generally better than a single Decision Tree because:\n",
    "\n",
    "It reduces overfitting by averaging predictions from multiple trees, which increases robustness.\n",
    "\n",
    "It handles larger datasets and more features effectively.\n",
    "\n",
    "It captures a broader range of data patterns due to the diversity among trees created by Bagging.\n",
    "\n",
    "It reduces variance while maintaining bias at a low level, leading to improved generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe3b6d",
   "metadata": {},
   "source": [
    "# 18. What is the difference between multiple model training and single model training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9086e",
   "metadata": {},
   "source": [
    "The main difference lies in the approach to building models:\n",
    "\n",
    "Single Model Training: Involves training one model on the entire dataset, focusing on learning from that specific dataset to predict outcomes.\n",
    "\n",
    "Multiple Model Training: Involves training several models (e.g., in ensemble methods) either on different subsets of the data or with different modeling techniques, allowing for the blending of predictions to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801c1a1",
   "metadata": {},
   "source": [
    "# 19. What are some real-world applications of ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf608e",
   "metadata": {},
   "source": [
    "Real-world applications of ensemble techniques include:\n",
    "\n",
    "Finance: Credit scoring, fraud detection.\n",
    "\n",
    "Healthcare: Disease diagnosis prediction, patient outcome forecasting.\n",
    "\n",
    "Marketing: Customer segmentation, churn prediction.\n",
    "\n",
    "Image Recognition: Object detection, facial recognition.\n",
    "\n",
    "Natural Language Processing: Sentiment analysis, text classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ee877",
   "metadata": {},
   "source": [
    "# 20. What is the difference between Bagging and Boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71318f4a",
   "metadata": {},
   "source": [
    "The differences between Bagging and Boosting are:\n",
    "\n",
    "Approach: Bagging trains multiple models in parallel using bootstrapped samples and combines them by averaging or voting. \n",
    "\n",
    "Boosting trains models sequentially, with each model focusing on the errors of its predecessor.\n",
    "\n",
    "Model Focus: Bagging reduces variance by averaging predictions, while Boosting reduces bias by learning iteratively from previous errors.\n",
    "\n",
    "Data Use: In Bagging, each model is trained independently on a random subset of data.\n",
    "\n",
    " In Boosting, each subsequent model adjusts to the mistakes of the previous models, often giving more weight to misclassified instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a523611",
   "metadata": {},
   "source": [
    "# *********************** Practical's ***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c9d4a",
   "metadata": {},
   "source": [
    "# 1. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5befc20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 1.00\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Bagging Classifier Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bf7db9",
   "metadata": {},
   "source": [
    "# 2. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7eb49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE: 38.29\n",
      "Bagging Regressor MAE: 3.88\n",
      "Bagging Regressor R2: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Regressor\n",
    "bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10)\n",
    "bagging_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = bagging_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Bagging Regressor MSE: {mse:.2f}\")\n",
    "print(f\"Bagging Regressor MAE: {mae:.2f}\")\n",
    "print(f\"Bagging Regressor R2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be2a4c",
   "metadata": {},
   "source": [
    "# 3. Train a Bagging Classifier using SVM as a base estimator and print accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9ca2c",
   "metadata": {},
   "source": [
    "# 4. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f66d5a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier AUC: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(estimator=LogisticRegression(max_iter=10000), n_estimators=10)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred_proba = bagging_clf.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Bagging Classifier AUC: {auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf22ff5",
   "metadata": {},
   "source": [
    "# 5. Train an ensemble model using both Bagging and Random Forest and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16909731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.98\n",
      "Random Forest Classifier Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=10)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "# Comparison with Bagging Classifier\n",
    "y_pred = bagging_clf.predict(X_test)\n",
    "bagging_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Bagging Classifier Accuracy: {bagging_accuracy:.2f}\")\n",
    "print(f\"Random Forest Classifier Accuracy: {rf_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfd83f",
   "metadata": {},
   "source": [
    "# 6. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d984a94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores:\n",
      "Feature mean radius: 0.0387\n",
      "Feature mean texture: 0.0160\n",
      "Feature mean perimeter: 0.0433\n",
      "Feature mean area: 0.0668\n",
      "Feature mean smoothness: 0.0076\n",
      "Feature mean compactness: 0.0109\n",
      "Feature mean concavity: 0.0743\n",
      "Feature mean concave points: 0.1289\n",
      "Feature mean symmetry: 0.0047\n",
      "Feature mean fractal dimension: 0.0050\n",
      "Feature radius error: 0.0079\n",
      "Feature texture error: 0.0055\n",
      "Feature perimeter error: 0.0121\n",
      "Feature area error: 0.0269\n",
      "Feature smoothness error: 0.0033\n",
      "Feature compactness error: 0.0036\n",
      "Feature concavity error: 0.0085\n",
      "Feature concave points error: 0.0035\n",
      "Feature symmetry error: 0.0049\n",
      "Feature fractal dimension error: 0.0051\n",
      "Feature worst radius: 0.1133\n",
      "Feature worst texture: 0.0207\n",
      "Feature worst perimeter: 0.0923\n",
      "Feature worst area: 0.0754\n",
      "Feature worst smoothness: 0.0101\n",
      "Feature worst compactness: 0.0133\n",
      "Feature worst concavity: 0.0434\n",
      "Feature worst concave points: 0.1368\n",
      "Feature worst symmetry: 0.0123\n",
      "Feature worst fractal dimension: 0.0048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rf_cancer = RandomForestClassifier(n_estimators=100)\n",
    "rf_cancer.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importance_scores = rf_cancer.feature_importances_\n",
    "print(\"Feature Importance Scores:\")\n",
    "for i, score in enumerate(importance_scores):\n",
    "    print(f\"Feature {cancer.feature_names[i]}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b239a77",
   "metadata": {},
   "source": [
    "# 7. Train a Random Forest Regressor and analyze feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4cebc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Scores for Random Forest Regressor:\n",
      "Feature 0: 0.3531\n",
      "Feature 1: 0.0449\n",
      "Feature 2: 0.0181\n",
      "Feature 3: 0.0434\n",
      "Feature 4: 0.0941\n",
      "Feature 5: 0.0329\n",
      "Feature 6: 0.0308\n",
      "Feature 7: 0.0971\n",
      "Feature 8: 0.1464\n",
      "Feature 9: 0.1392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# Create a regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance\n",
    "importance_scores = rf_reg.feature_importances_\n",
    "print(\"Feature Importance Scores for Random Forest Regressor:\")\n",
    "for i, score in enumerate(importance_scores):\n",
    "    print(f\"Feature {i}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41e63b",
   "metadata": {},
   "source": [
    "# 8. Train a Random Forest Regressor and compare its performance with a single Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a337489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor MSE: 16609.60\n",
      "Decision Tree Regressor MSE: 24055.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Train Decision Tree Regressor\n",
    "dt_reg = DecisionTreeRegressor()\n",
    "dt_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Random Forest Regressor\n",
    "rf_pred = rf_reg.predict(X_test)\n",
    "rf_mse = mean_squared_error(y_test, rf_pred)\n",
    "\n",
    "# Evaluate Decision Tree Regressor\n",
    "dt_pred = dt_reg.predict(X_test)\n",
    "dt_mse = mean_squared_error(y_test, dt_pred)\n",
    "\n",
    "print(f\"Random Forest Regressor MSE: {rf_mse:.2f}\")\n",
    "print(f\"Decision Tree Regressor MSE: {dt_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b69d29",
   "metadata": {},
   "source": [
    "# 9. Train a Random Forest Classifier with different numbers of trees and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3843d300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy with 10 trees: 0.95\n",
      "Random Forest Classifier Accuracy with 50 trees: 0.96\n",
      "Random Forest Classifier Accuracy with 100 trees: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier with different n_estimators\n",
    "tree_counts = [10, 50, 100]\n",
    "for n in tree_counts:\n",
    "    rf_clf = RandomForestClassifier(n_estimators=n)\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Random Forest Classifier Accuracy with {n} trees: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9021578",
   "metadata": {},
   "source": [
    "# 10. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "031985f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Classifier with OOB\n",
    "rf_oob_clf = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "rf_oob_clf.fit(X_train, y_train)\n",
    "\n",
    "# OOB score\n",
    "print(f\"OOB Score: {rf_oob_clf.oob_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2557c",
   "metadata": {},
   "source": [
    "# 11. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35bebac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Classifier Accuracy: 0.96\n",
      "Decision Tree Classifier Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Bagging Classifier\n",
    "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10)\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "bagging_pred = bagging_clf.predict(X_test)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "\n",
    "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "print(f\"Bagging Classifier Accuracy: {bagging_accuracy:.2f}\")\n",
    "print(f\"Decision Tree Classifier Accuracy: {dt_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77dbf7f",
   "metadata": {},
   "source": [
    "# 12. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9140cb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.96, Recall: 0.96, F1 Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate performance with metrics\n",
    "precision = precision_score(y_test, bagging_pred, average='weighted')\n",
    "recall = recall_score(y_test, bagging_pred, average='weighted')\n",
    "f1 = f1_score(y_test, bagging_pred, average='weighted')\n",
    "\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080de59",
   "metadata": {},
   "source": [
    "# 13. Train a Bagging Classifier and evaluate its performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d89302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.92982456 0.94736842 0.98245614 0.94736842 0.95575221]\n",
      "Mean CV score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(bagging_clf, X, y, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV score: {cv_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebaa32",
   "metadata": {},
   "source": [
    "# 14. Train a Bagging Regressor with different numbers of base estimators and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97ef92fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Regressor MSE with 10 base estimators: 4.57\n",
      "Bagging Regressor MSE with 50 base estimators: 3.90\n",
      "Bagging Regressor MSE with 100 base estimators: 3.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Evaluating Bagging Regressor with different n_estimators\n",
    "for n in [10, 50, 100]:\n",
    "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=n)\n",
    "    bagging_reg.fit(X_train, y_train)\n",
    "    y_pred = bagging_reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Bagging Regressor MSE with {n} base estimators: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec269b2b",
   "metadata": {},
   "source": [
    "# 15. Train a Bagging Regressor using different base estimators (Decision Tree and KNeighbors) and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea4931bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Bagging Regressor with Decision Tree: 7.74\n",
      "MSE for Bagging Regressor with KNeighbors: 104.24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree Bagging Regressor\n",
    "bagging_dt = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10)\n",
    "bagging_dt.fit(X_train, y_train)\n",
    "y_pred_dt = bagging_dt.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "\n",
    "# KNeighbors Bagging Regressor\n",
    "bagging_knn = BaggingRegressor(estimator=KNeighborsRegressor(), n_estimators=10)\n",
    "bagging_knn.fit(X_train, y_train)\n",
    "y_pred_knn = bagging_knn.predict(X_test)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"MSE for Bagging Regressor with Decision Tree: {mse_dt:.2f}\")\n",
    "print(f\"MSE for Bagging Regressor with KNeighbors: {mse_knn:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385accc9",
   "metadata": {},
   "source": [
    "# 16. Train a Bagging Regressor with different levels of bootstrap samples and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ba42ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Bagging Regressor with bootstrap=True: 145.59\n",
      "MSE for Bagging Regressor with bootstrap=False: 131.22\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Trying different bootstrap settings: True and False\n",
    "for bootstrap in [True, False]:\n",
    "    bagging_reg = BaggingRegressor(estimator=DecisionTreeRegressor(), n_estimators=10, bootstrap=bootstrap)\n",
    "    bagging_reg.fit(X_train, y_train)\n",
    "    y_pred = bagging_reg.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"MSE for Bagging Regressor with bootstrap={bootstrap}: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b46f43",
   "metadata": {},
   "source": [
    "# 17. Train a Random Forest Classifier and visualize the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3e7d2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest classifier\n",
    "rf_cancer = RandomForestClassifier(n_estimators=100)\n",
    "rf_cancer.fit(X_train, y_train)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, rf_cancer.predict(X_test))\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=cancer.target_names)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b3d8d",
   "metadata": {},
   "source": [
    "# 18. Train a Random Forest Classifier and print the top 5 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5daa48da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Feature Importances:\n",
      "Feature: worst area, Importance: 0.0814\n",
      "Feature: worst perimeter, Importance: 0.1121\n",
      "Feature: worst concave points, Importance: 0.1281\n",
      "Feature: worst radius, Importance: 0.1344\n",
      "Feature: mean concave points, Importance: 0.1418\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest classifier\n",
    "rf_cancer = RandomForestClassifier(n_estimators=100)\n",
    "rf_cancer.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_cancer.feature_importances_\n",
    "indices = np.argsort(importances)[-5:]  # Get top 5\n",
    "\n",
    "print(\"Top 5 Feature Importances:\")\n",
    "for i in indices:\n",
    "    print(f\"Feature: {cancer.feature_names[i]}, Importance: {importances[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa462594",
   "metadata": {},
   "source": [
    "# 19. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "152e24d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 10, 'n_estimators': 50}, Best Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_accuracy = accuracy_score(y_test, best_rf.predict(X_test))\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}, Best Accuracy: {best_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2172adea",
   "metadata": {},
   "source": [
    "# 20. Train a Random Forest Classifier and analyze misclassified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4760108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified Samples:\n",
      "Sample index: 8, True label: 1, Predicted label: 0\n",
      "Sample index: 20, True label: 0, Predicted label: 1\n",
      "Sample index: 77, True label: 0, Predicted label: 1\n",
      "Sample index: 82, True label: 0, Predicted label: 1\n",
      "Sample index: 108, True label: 1, Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest classifier\n",
    "rf_cancer = RandomForestClassifier(n_estimators=100)\n",
    "rf_cancer.fit(X_train, y_train)\n",
    "\n",
    "# Find misclassified samples\n",
    "misclassified_indices = np.where(y_test != rf_cancer.predict(X_test))[0]\n",
    "print(\"Misclassified Samples:\")\n",
    "for i in misclassified_indices:\n",
    "    print(f\"Sample index: {i}, True label: {y_test[i]}, Predicted label: {rf_cancer.predict(X_test)[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c129e",
   "metadata": {},
   "source": [
    "# 21. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e91bf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with max_depth=None: 0.96\n",
      "Accuracy with max_depth=5: 0.96\n",
      "Accuracy with max_depth=10: 0.96\n",
      "Accuracy with max_depth=15: 0.96\n",
      "Accuracy with max_depth=20: 0.96\n"
     ]
    }
   ],
   "source": [
    "max_depths = [None, 5, 10, 15, 20]\n",
    "for depth in max_depths:\n",
    "    rf_depth = RandomForestClassifier(max_depth=depth, n_estimators=100)\n",
    "    rf_depth.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, rf_depth.predict(X_test))\n",
    "    print(f\"Accuracy with max_depth={depth}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ab7a4",
   "metadata": {},
   "source": [
    "# 22. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49fd8109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Calculate ROC-AUC score\n",
    "y_pred_proba = rf_cancer.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC-AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb61791a",
   "metadata": {},
   "source": [
    "# 23. Train a Random Forest Classifier and plot the Precision-Recall curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca7dcec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP5hJREFUeJzt3Qd8FHXex/FfCKRRQgldIHREmoLkImA7NIB6Aj4YAWlSROQ5hVMERJonUU85LBTlpOjjSRAip8KBFFERkKYeKJ1AKCEQlACBJJDM8/r9cfeyySaSkGSzmc/79Vp3Z3ZmMjMbs1/+1ceyLEsAAABspJSnTwAAAKCoEYAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAAuDVw4EAJDQ3N0z7r168XHx8f84zs7rzzTvNwOHz4sLlfCxYs8Oh5AXZEAAKKCf0S1C9DxyMgIECaNGkiI0eOlISEBE+fXrHnCBOOR6lSpaRy5crStWtX2bRpk5QE+nvwzDPPSLNmzSQoKEjKli0rbdu2lb/+9a9y9uxZT58e4FVKe/oEALiaOnWq1K9fX1JSUmTDhg0ye/ZsWbFihezatct86RWVuXPnSkZGRp72uf322+XSpUvi5+cnntK7d2/p1q2bpKeny759+2TWrFly1113ydatW6Vly5birfT89bouXLggjz76qAk+atu2bfLyyy/L119/LV988YWnTxPwGgQgoJjREot27dqZ10OGDJEqVarI9OnT5V//+pf5cncnOTnZlAYUpDJlyuR5Hy110ZIrT7rllltMQHDo1KmTuacaJDUMeSMt3enRo4f4+vrK999/b0qAMnvppZdMYC0IhfG7BBRHVIEBxdzdd99tnmNjY51tc8qVKycHDx40JQLly5eXvn37mve0xGbGjBly0003mSBSvXp1efzxx+XXX3/Ndtx///vfcscdd5j9K1SoILfeeqv885//zLUN0KJFi0zJg2MfLVF54403frcN0Mcff2z2CwwMlJCQEBNQjh8/7rKN47p0fffu3c3rqlWrmiofLc3JLw1ASu9X1lDx9NNPS506dcTf318aNWokr7zySrZSL13Wa9Rr1Xuq59SlSxdT8uIwf/588zlVq1bNHKt58+YmcBWUd955x9wXDcJZw4/Sz3nChAnOZf0MJk+enG07/Tz1Pmetdv3qq69kxIgR5vxvuOEGWbJkiXO9u3PR97RE0mHPnj3yP//zP6bKUe+RBvhPP/20gK4eKByUAAHFnOOLW0uCHK5cuSIRERHSsWNHee2115xVYxp29Ett0KBB8uc//9mEprffftuUGnz77bfOUh3d5rHHHjNBady4cVKxYkWzzcqVK6VPnz5uz2P16tWmBOqPf/yjCQpq9+7d5rhPPfVUjufvOB8NWFFRUaYdiwYK3U9/pv5sBw06el1hYWHmutasWSOvv/66NGzYUJ544ol8tw1SlSpVcq67ePGiCX8aKvSe1a1bVzZu3GjuRXx8vAmRDoMHDzbXoKVIWiKn9/6bb76RzZs3O0vqNOzovfzTn/4kpUuXls8++8wECg1PTz75pFwvDRMaHjVkFAY9Vw12EydONCVA9913nwmgixcvNvcps+joaHOtLVq0MMs//fSTdOjQQWrXri1jx441pUe6n4bYpUuXmpIroFiyABQL8+fPt/R/yTVr1linT5+2jh49ai1atMiqUqWKFRgYaB07dsxsN2DAALPd2LFjXfb/5ptvzPoPP/zQZf3KlStd1p89e9YqX768FRYWZl26dMll24yMDOdr/Tn16tVzLj/11FNWhQoVrCtXruR4DV9++aX5Wfqs0tLSrGrVqlktWrRw+Vmff/652W7ixIkuP0/XTZ061eWYN998s9W2bdvfvX+xsbFm/ylTppj7d/LkSXNPbr31VrP+448/dm774osvWmXLlrX27dvncgy9p76+vlZcXJxZXrdundn3z3/+c7afl/leXbx4Mdv7ERERVoMGDVzW3XHHHeaR9Zz1s89NpUqVrNatW1vXSo85adKkbOv189T7nPV3rmPHjtk+1969e5vPLvP6+Ph4q1SpUi6f0R//+EerZcuWVkpKisu9ue2226zGjRtf8zkDRY0qMKCY6dy5s/nXuFbNPPLII+Zf4p988on5F3ZmWUtEtJopODhY7rnnHklMTHQ+tOpJj/Hll186S3LOnz9v/rWetb2OVm3kREtqtHRA979WWk106tQpU8KQ+WdpCYNW5SxfvjzbPsOHD89WhXXo0KFr/pmTJk0y969GjRpmXy2l0lKkzKUneq/0PS0Vynyv9N5rKZQ2KFZagqH3RI+ZVeZ7paUzDklJSeZYWnKi563L1+vcuXOm2rGwDB061LQvyiwyMtJ8dpmrM7VqTEu19D31yy+/yLp16+Thhx82v1OO+3jmzBlTkrd///5sVZ1AcUEVGFDMzJw503R/16oUbdvRtGlT07g4M31P22pkpl82+mWr7Tjc0S+zzFVqjiqMa6UhRqs2tCpIw9i9995rvvi0PUxOjhw5Yp71GrLSAKS93DJztLHJTENK5jZMp0+fdmkTpOFOHw7Dhg2TXr16mV50+uX85ptvZmtDpPfqP//5T7af5e5e1apVy7RtyY1W52lI0u72Wr2WmX4mGkyvh7a30oBRWLTXYVb6uep5a5WXVnsqfd2mTRvz+6kOHDigtQjywgsvmEdO9zJreAeKAwIQUMy0b9/e2bYkJ9rQNmso0n+Za/j58MMP3e6T05f9tdJj//DDD7Jq1SrTgFof2vi3f//+snDhQikIWUsh3NG2RI5gpTR4ZG7w27hxY1OSo+6//35zTC3t0q7wjvuq90pLysaMGeP2Zzi+4K+FhiQNCBrotJGyltzpMAA6dMHf//73PA8l4I4eW+99WlradQ0xkFNj8swlWJl/x7Qdj5Y+au85bbulQW/atGnObRzXpg3VtcTHHW1cDhRHBCCghNCGwtpoWBukuvtCy7yd0l48ef1y0i/fBx54wDz0y09LhbRXkP7r392x6tWrZ5737t3r7M3moOsc7+eFBjwda8ihQYMGuW7//PPPmy7i2ktKG3k77oGOp+MISjnR7TTwaVVPTqVA2uA5NTXVNFTWxtQOjirHgqD3W0uXtEoup6EQspaaZR0YUcOTNvDOC63q0nC7du1aU5WopT2O6q/M914b1//evQSKG9oAASWEVkfpv/BffPHFbO9pzyXHF6JWXWl7Eu2RpdVEmV1tP+uetuvITEugWrVqZV5rAHBHS1y05GjOnDku22jpkX6halugvNKAp1+2jsfvBSBtu6Q9vTTIaCmK415poNB1Wel90vulHnroIXNPpkyZkm07x71ylFplvnda7aWlYwVF20XVrFlT/vKXv5jBHd1VM+lo0JmDm6Mdk8O7776b5+EE9P5q8NOqL31o6WTm6jL9bHVqDw3B7sKVVlcCxRUlQEAJoY1u9Yteg41+0WvQ0X+Za3sXbfSrXc+1IbC2J9GqGe3SrdVJ2u1dSwx+/PFH034lp+os3V5LQrQkR9sfaTXUW2+9ZdqE3HjjjW730Z+vXea1G7yen5ZeOLrB65g0o0aNkqKg3fS1a7uOmKxjGT377LOmxEaryHRcHG0org28d+7caRr6atd5Ha9Iq8369etn2hHpfdR2MVrypd3g9T2dpkTvs6NkTO+/lixpiZOGg7yWuOREPx+titJxn/R+Zx4JeseOHfLRRx9JeHi4y2eloUkDnFb16WerYU+vKS/08+vZs6e5Z3p/dGgCd23WdDgGHSdJG1NrINXPWAPmsWPHzM8GiqUi73cGwC1Hl+StW7fmup12Y9Yu3Dl59913Tbdx7Tqv3d21i/KYMWOsEydOuGz36aefmq7Kup12b2/fvr310Ucf5dgNfsmSJda9995rukb7+flZdevWtR5//HHTNTqnbvAO0dHRpju7v7+/VblyZatv377Obv2/d13anfta/lQ5upT/7W9/c/v+wIEDTRf3AwcOmOXz589b48aNsxo1amSuJyQkxNyP1157zXTfd9Bu4HrMZs2ame2qVq1qde3a1dq+fbvLvWzVqpUVEBBghYaGWq+88oo1b948cz56XtfbDd5BP8NRo0ZZTZo0MT8rKCjIfNYvvfSSlZSU5NwuPT3deu6558w16TbaJV+vO6du8Ln9zq1evdps4+PjY4ZmcOfgwYNW//79rRo1alhlypSxateubd1///3mdwYornz0P54OYQAAAEWJNkAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2CEAAAMB2GAjRDR3o7MSJE2a03NxmxwYAAMWHjuyjEwfrJMZZ50vMigDkhoYfndAQAAB4n6NHj5oR63NDAHJDS34cN1CnDQAAAMXfuXPnTAGG43s8NwQgNxzVXhp+CEAAAHiXa2m+QiNoAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOwQgAABgOx4NQF9//bU88MADZtZWHbZ62bJlv7vP+vXr5ZZbbhF/f39p1KiRLFiwINs2M2fOlNDQUAkICJCwsDDZsmVLIV0BAADwRh4NQMnJydK6dWsTWK5FbGys3HfffXLXXXfJDz/8IE8//bQMGTJEVq1a5dwmOjpaRo8eLZMmTZIdO3aY40dERMipU6ekOIhPuiQbDyaaZ8AbeePvsDeec16vxQ7XWJD75LZ9URwrP59jSfqMiwMfy7IsKQa0BOiTTz6R7t2757jNc889J8uXL5ddu3Y51z3yyCNy9uxZWblypVnWEp9bb71V3n77bbOckZFhZob93//9Xxk7duw1zyYbHBwsSUlJBToZ6oKNsTL1s58lwxIp5SMyJqKp3N+6VoEdHyhsn/94Ql5dtderfoe98Zzzei12uMaC3Ce37YviWPn5HLO+F9WzpUTeWjefd7nkysv3t1cFoNtvv91Uf82YMcO5bv78+aYkSC82LS1NgoKCZMmSJS7HGTBggAlJ//rXv9weNzU11Twy30ANTQUZgDSx3xa1TorFzQYAeDVfHx/ZMPYuqRkc6OlT8doAVFq8yMmTJ6V69eou63RZL/jSpUvy66+/Snp6uttt9uzZk+Nxo6KiZMqUKVKYYhOT3YafMqV8pJTGeaCYy8iw5LL+89OLfoe98Zzzei2+PiLpbv64lKRrzO1a8rpPbturwj5WTp9Xbp+ju2OlW5YcTrxIALoOXhWACsu4ceNMu6GsJUAFqX5IWVNsmfl3WBP818+R4OEdtBSzw8vrvOp32BvPOa/XEjMiXHrM2liirzG3a8nrPrltrwr7WDl9Xrl9jiprDYK+FxoS5PaeoAR2g69Ro4YkJCS4rNNlLeYKDAyUkJAQ8fX1dbuN7psT7VGmx8j8KGj6P4/W2eovrdLnaT1beN0fKNiXN/4Oe+M55/VaWtepVOKvMbdryes+uW1fFMfK6fPK7XPUR692Nzh/rjd/xsWJ1zWCXrFihezcudO5rk+fPvLLL7+4NIJu3769vPXWW85G0HXr1pWRI0d6vBG0418MWmypyZ1fXngjb/wd9sZzzuu12OEaC3Kf3LYvimPldf3S7cfkLx//KK1uCJZ3+rX1+s9Y7N4G6MKFC3LgwAGXbu7avb1y5comtGjV1PHjx+X999837w8fPtz07hozZow89thjsm7dOlm8eLHpGeagVVna6Lldu3YmCGmDae1uP2jQICkOHGke8Fbe+Dvsjeec12uxwzUW5D65bV8Ux8rv51gxyK/EfM6e5tEAtG3bNjOmj4OjHY4GGB3gMD4+XuLi4pzv169f34SdUaNGyRtvvCE33HCD/OMf/zDj/DhERkbK6dOnZeLEiabRdJs2bUzpUNaG0QAAwL6KTRVYcVKYVWAAAOSVowrs9iZV5f3H2nv6dErE97dXNYIGAAAoCAQgAABgOwQgAABgOwQgAABKoIKcpLUkYiRoAAC8xNmLaSacZB07SKdb0hkHHOujt8bJuJidbidPzem96Fz2KYnoBeYGvcAAAMXJmCU/yuJtx8xrHSy6/x/qSfv6VeSrfafk423HzDQZOob03TdWMyHow81Hss0/2T60kqRdseSHY2ezHT+gTClJuZzh9ROues1AiAAAIHdawqMhx0GLLRZuOmIemWngWbv7VI7H2XL41xzfS8kSfuww4SptgAAAKMa0estdVU2dSu6DyV1Nq5rSoMy01GjSAzfKSz1amNeZaXXX7L43m+es60vyhKsEIAAAijFt25M1nGj11Nt9soeWqxOltpSXH3KdWPXlni1lUIcG0jesnnntm+k9bevTtWWt3yZj/e+x7mhStcSW/ijaALlBGyAAQHGiDZTHx+wy1VKO2eAdDZfdrb+eSVqXbj8mr32xT4L8fOXrMXdJSDl/KYnf3wQgNwhAAIDiJq8zyOeXZVnSfea38uOxJBnSsb5MuL+5eAumwgAAoITRcBPesEq2kJPT+vzy8fGR0fc2Na8/2HxEEs6lSElEAAIAAC5ubxwi7epVktQrGTLzywNSEhGAAABAtlKgv/xWCvTRljg59utFKWkIQAAAIButVuvQqIpcTrfk7XUlrxSIAAQAANwafc/VUqDF247KJzuO5WleseKOkaABAIBbbetVkqbVy8nehAsyavGP1zyvmDcgAAEAALe0VGffqQvOZQ06zy3daRpGX0hNl1+S01ze0zGJbveSARSpAgMAADlPw+FmtMC4Xy65hJ+s84d5AwIQAAC45mk4dHlWn5tl4aBbs805pqNRe8v8YQQgAADgllZlRbmZO6xbq1pyR9NqMqRTfee2jqk4vKH6S9EGCAAA5EgbNWu7HnfTbdzZtJrM/SbWzEy/eHi414QfRQACAAC50mCTW7gJ8ivtVeFHUQUGAABshwAEAABshwAEAABshwAEAABshwAEAACuy8W0K9nmAivuc4TRCwwAAOTL+r2nzPPRXy9Jh5fXyeN3NJCb61SSVT+dlJgdx0UHkS6uc4QRgAAAQJ5pyc4/NsS6zAU2e/2hbNsV1znCqAIDAAAFNk9YreAAr5gjjAAEAAAKZJ4wnQ5j9qO3ZFuvi8VtjjACEAAAKJB5wnQusNZ1KrmsV6V9s06b6nkeD0AzZ86U0NBQCQgIkLCwMNmyZUuO216+fFmmTp0qDRs2NNu3bt1aVq5c6bLN5MmTxcfHx+XRrFmzIrgSAADsJfLWurJh7F3y0dA/mGdHQ+f/rg+T1jcEy+V0S6JW7JHixKMBKDo6WkaPHi2TJk2SHTt2mEATEREhp05dbVWe1YQJE+Sdd96Rt956S37++WcZPny49OjRQ77//nuX7W666SaJj493PjZs2FBEVwQAgP1KgsIbVsnWwPnq+hB5qUdL0cKgT388IVtif5HiwqMBaPr06TJ06FAZNGiQNG/eXObMmSNBQUEyb948t9t/8MEHMn78eOnWrZs0aNBAnnjiCfP69ddfd9mudOnSUqNGDecjJCSkiK4IAABk1qJ2sDzyW8nQ5E9/knTtFmbnAJSWlibbt2+Xzp07//dkSpUyy5s2bXK7T2pqqqn6yiwwMDBbCc/+/fulVq1aJiT17dtX4uLicj0XPe65c+dcHgAAoGA8c28TKR9QWn6OPyfRW4+KrQNQYmKipKenS/Xq1V3W6/LJkyfd7qPVY1pqpAEnIyNDVq9eLTExMaaay0HbES1YsMC0DZo9e7bExsZKp06d5Pz58zmeS1RUlAQHBzsfderUKcArBQDA3qqU85dRnZuY16+u3COrf0rw+AjRHm8EnRdvvPGGNG7c2DRq9vPzk5EjR5rqMy05cujatav06tVLWrVqZQLTihUr5OzZs7J48eIcjztu3DhJSkpyPo4eLR7pFACAkqJfeD2pVt5fzl66LEM/2GZGjo7emnsNTYkMQNoux9fXVxISElzW67K223GnatWqsmzZMklOTpYjR47Inj17pFy5cqaqKycVK1aUJk2ayIEDB3Lcxt/fXypUqODyAAAABSfxQqqcvpCabYRoT5UEeSwAaQlO27ZtZe3atc51Wq2ly+Hh4bnuq+2AateuLVeuXJGlS5fKgw8+mOO2Fy5ckIMHD0rNmjUL9PwBAMD1jRztyRGiPVoFpl3g586dKwsXLpTdu3ebXl1auqPVWqp///6mesrhu+++M21+Dh06JN9884106dLFhKYxY8Y4t3nmmWfkq6++ksOHD8vGjRtNN3ktaerdu7dHrhEAAEiOI0d7aoRoj06GGhkZKadPn5aJEyeahs9t2rQxjZcdDaO191bm9j0pKSlmLCANQFr1pV3gtWu8VnM5HDt2zISdM2fOmCqzjh07yubNm81rAADgGY6Ro8cu3WlmidcspCNHe2qCVB/LcjeVmb1pN3jtDaYNomkPBABAwXluyX8kettR6f+HejK1ewuPfX97VS8wAADg3cr6X618Khfg0UooAhAAALAfAhAAALAdAhAAALAdAhAAALAdAhAAACgyyalXzPOFlKvPnkIAAgAARULn/lq87ep8mx9sPmLPucAAAIB9xCddknExVwdBVPpsy7nAAACAveYCy2AuMAAAYCf1i9lcYAQgAABQZHOBOTKQp+cCIwABAIAiEXlrXXm4XR3zut8f6pllTyEAAQCAIsNcYAAAAB5CAAIAALZDAAIAAEWGkaABAICtRDMSNAAAsJN4RoIGAAB2E8tI0AAAwG7qMxI0AACwm5qMBA0AAOwokpGgAQCAHZVlJGgAAADPIAABAADbIQABAADbIQABAIAiw1QYAADAVqKZCgMAANhJPFNhAAAAu4llKgwAAGA39ZkKAwAA2E1NpsIAAAB2FMlUGAAAwI7KMhXGVTNnzpTQ0FAJCAiQsLAw2bJlS47bXr58WaZOnSoNGzY027du3VpWrlx5XccEAAD249EAFB0dLaNHj5ZJkybJjh07TKCJiIiQU6dOud1+woQJ8s4778hbb70lP//8swwfPlx69Ogh33//fb6PCQAA7MejAWj69OkydOhQGTRokDRv3lzmzJkjQUFBMm/ePLfbf/DBBzJ+/Hjp1q2bNGjQQJ544gnz+vXXX8/3MQEAgP14LAClpaXJ9u3bpXPnzv89mVKlzPKmTZvc7pOammqqtTILDAyUDRs25PuYjuOeO3fO5QEAAEoujwWgxMRESU9Pl+rVq7us1+WTJ0+63UersrSEZ//+/ZKRkSGrV6+WmJgYiY+Pz/cxVVRUlAQHBzsfdepcbaEOAABKJo83gs6LN954Qxo3bizNmjUTPz8/GTlypKnq0lKe6zFu3DhJSkpyPo4evTpPCQAAKJk8FoBCQkLE19dXEhISXNbrco0aNdzuU7VqVVm2bJkkJyfLkSNHZM+ePVKuXDnTHii/x1T+/v5SoUIFlwcAACi5PBaAtASnbdu2snbtWuc6rdbS5fDw8Fz31XZAtWvXlitXrsjSpUvlwQcfvO5jAgAA+/DoKETaXX3AgAHSrl07ad++vcyYMcOU7mi1lurfv78JOtpGR3333Xdy/PhxadOmjXmePHmyCThjxoy55mMCAAB4NABFRkbK6dOnZeLEiaaRsgYbHdjQ0Yg5Li7OpX1PSkqKGQvo0KFDpupLu8Br1/iKFSte8zEBAAB8LMvKMjk9tBu89gbTBtG0BwIAoOBM/exnmfdtrIy4s6GM6dLMY9/fXtULDAAAoCAQgAAAQJFJTr1ini+kXH32FAIQAAAoEtFb42Txtqtj7X2w+YhZ9hQCEAAAKHTxSZdkXMxOcTQ81ufxMbvMek8gAAEAgEIXm5gsGVm6XaVblhxOvCieQAACAACFrn5IWSnl47rO18dHQkOCxBMIQAAAoNDVDA6UqJ4txZGB9HlazxZmvScQgAAAQJGIvLWuPNyujnnd7w/1zLKnEIAAAECRKet/dRKKcgEenYyCAAQAAOyHAAQAAGyHAAQAAIoMI0EDAABbiWYkaAAAYCfxjAQNAADsJpaRoAEAgN3UZyRoAABgNzUZCRoAANhRJCNBAwAAOyrLSNAAAACeQQACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAAC2QwACAABFJjn1inm+kHL12VMIQAAAoEhEb42TxduOmtcfbD5ilj2FAAQAAApdfNIlGRezU6zflvV5fMwus96WAWjmzJkSGhoqAQEBEhYWJlu2bMl1+xkzZkjTpk0lMDBQ6tSpI6NGjZKUlBTn+5MnTxYfHx+XR7NmzYrgSgAAQE5iE5Mlw5F+fpNuWXI48aJ4QmnxoOjoaBk9erTMmTPHhB8NNxEREbJ3716pVq1atu3/+c9/ytixY2XevHly2223yb59+2TgwIEm5EyfPt253U033SRr1qxxLpcu7dHLBADA9uqHlJVSPuISgnx9fCQ0JMh+JUAaWoYOHSqDBg2S5s2bmyAUFBRkAo47GzdulA4dOkifPn1MqdG9994rvXv3zlZqpIGnRo0azkdISEgRXREAAHCnZnCgRPVsKT6/LevztJ4tzHpbBaC0tDTZvn27dO7c+b8nU6qUWd60aZPbfbTUR/dxBJ5Dhw7JihUrpFu3bi7b7d+/X2rVqiUNGjSQvn37Slyc5xpZAQCAqyJvrSsPt6tjXvf7Qz2z7CkeqxtKTEyU9PR0qV69ust6Xd6zZ4/bfbTkR/fr2LGjWJYlV65ckeHDh8v48eOd22hV2oIFC0w7ofj4eJkyZYp06tRJdu3aJeXLl3d73NTUVPNwOHfuXIFdJwAA+K+y/lejR7kAzzZP8Xgj6LxYv369TJs2TWbNmiU7duyQmJgYWb58ubz44ovObbp27Sq9evWSVq1amfZEWkJ09uxZWbx4cY7HjYqKkuDgYOdDG1cDAICSy2PxS9vl+Pr6SkJCgst6XdZ2O+688MIL0q9fPxkyZIhZbtmypSQnJ8uwYcPk+eefN1VoWVWsWFGaNGkiBw4cyPFcxo0bZxpjZy4BIgQBAFByeawEyM/PT9q2bStr1651rsvIyDDL4eHhbve5ePFitpCjIUpplZg7Fy5ckIMHD0rNmjVzPBd/f3+pUKGCywMAAJRcHq2A01KXAQMGSLt27aR9+/amG7yW6GivMNW/f3+pXbu2qaJSDzzwgOk5dvPNN5u2Plqqo6VCut4RhJ555hmzXK9ePTlx4oRMmjTJvKe9xQAAADwegCIjI+X06dMyceJEOXnypLRp00ZWrlzpbBitvbcyl/hMmDDBjPmjz8ePH5eqVauasPPSSy85tzl27JgJO2fOnDHva4PpzZs3m9cAAADKx8qp7sjGtA2QNoZOSkqiOgwAgAI09bOfZd63sTLizoYypkszj31/e1UvMAAAAI9Vgen4PTrWjjZYPnXqlGm8nNm6desK5OQAAACKTQB66qmnTAC67777pEWLFqZdDgAAQIkOQIsWLTIDC2adggIAAMAblMrvGD6NGjUq+LMBAAAlWnLqFfN8IeXqs1cFoL/85S/yxhtv5Dj4IAAAQFbRW+Nk8baj5vUHm4+YZa+qAtuwYYN8+eWX8u9//1tuuukmKVOmjMv7OkcXAACAQ3zSJRkXs1McRSf6PD5ml9zepKrUDA4UrwhAOr9Wjx49Cv5sAABAiRSbmCwZWSqO0i1LDide9J4ANH/+/II/EwAAUGLVDykrpXzEJQT5+vhIaEiQR87nugZC1GkstDpMH/oaAADAHS3lierZUhwD5+jztJ4tPFL6k+8ApBOWPvbYY2aG9dtvv908atWqJYMHDzYztgMAAGQVeWtdebhdHfO63x/qmWVPKZXfWdy/+uor+eyzz+Ts2bPm8a9//cus0x5iAAAA7pT1v9r6plyAR+djz18boKVLl8qSJUvkzjvvdK7TQREDAwPl4YcfltmzZxfkOQIAAHi+BEiruapXr55tfbVq1agCAwAAJTMAhYeHy6RJkyQlJcW57tKlSzJlyhTzHgAAQHGWryowHQU6IiJCbrjhBmndurVZ9+OPP0pAQICsWrWqoM8RAADA8wFIZ4Dfv3+/fPjhh7Jnzx6zrnfv3tK3b1/TDggAAKA4y3cT7KCgIBk6dGjBng0AAEBxCkCffvqpdO3a1cz7pa9z86c//akgzg0AAMCzAah79+5y8uRJ09NLX+fEx8dH0tPTC+r8AAAAPBeAMjIy3L4GAADwNtc1F1hmOho0AABAiQ1Ar7zyikRHRzuXe/XqJZUrV5batWub7vAAAAAlLgDNmTNH6tS5OpnZ6tWrZc2aNbJy5UrTSPrZZ58t6HMEAADwfDd4bQztCECff/65mf/r3nvvldDQUAkLCyvYMwQAACgOJUCVKlWSo0ePmtda8tO5c2fz2rIseoABAICSWQLUs2dP6dOnjzRu3FjOnDljqr7U999/L40aNSrocwQAAPB8APr73/9uqru0FOjVV1+VcuXKmfXx8fEyYsSIgj1DAACA4hCAdDToZ555Jtv6UaNGFcQ5AQAAFCqmwgAAALbDVBgAAMB2mAoDAADYToFNhQEAAFCiA9Cf//xnefPNN7Otf/vtt+Xpp58uiPMCAAAoXgFo6dKl0qFDh2zrb7vtNlmyZEmejjVz5kzTpT4gIMCMIr1ly5Zct58xY4Y0bdpUAgMDzWjU2vMsJSXluo4JAADsJV8BSAc/DA4Ozra+QoUKkpiYeM3H0QlVR48eLZMmTZIdO3ZI69atJSIiQk6dOuV2+3/+858yduxYs/3u3bvlvffeM8cYP358vo8JAADsJ18BSEd71ikwsvr3v/8tDRo0uObjTJ8+XYYOHSqDBg2S5s2bm0lWg4KCZN68eW6337hxoyl50lGotYRH5x/r3bu3SwlPXo8JAADsJ18DIWoJy8iRI+X06dNy9913m3Vr166V119/3VRRXYu0tDTZvn27jBs3zrmuVKlSZl6xTZs2ud1Hq9j+7//+zwSe9u3by6FDh2TFihXSr1+/fB9TpaammofDuXPnrukaAACAjQLQY489ZgLDSy+9JC+++KJZpyUys2fPlv79+1/TMbSqTMcLql69ust6Xd6zZ4/bfbTkR/fr2LGjmXj1ypUrMnz4cGcVWH6OqaKiomTKlCnXdN4AAMDG3eCfeOIJOXbsmCQkJJgSEy2Nudbwk1/r16+XadOmyaxZs0z7npiYGFm+fLkzhOWXlhglJSU5H46Z7gEAQMmUrxIgpaUvGkgOHjxoSmbUiRMnTENox+SouQkJCRFfX18ToDLT5Ro1arjd54UXXjDVXUOGDDHLLVu2lOTkZBk2bJg8//zz+Tqm8vf3Nw8AAGAP+SoBOnLkiAkfDz74oDz55JOmLZB65ZVX3E6S6o6fn5+0bdvWtB3KPMK0LoeHh7vd5+LFi6ZNT2YaeJRWieXnmAAAwH7yFYCeeuopadeunfz6669mPB6HHj16uISPa2lMPXfuXFm4cKHp1q7Valqioz24lFapZW7Q/MADD5h2RosWLZLY2FhZvXq1KRXS9Y4g9HvHBAAAyFcV2DfffGO6pGuJS2baEPr48ePXfJzIyEhTejRx4kQz0WqbNm1M93pHI+a4uDiXEp8JEyaYyVb1WX9O1apVTfjRxtjXekwAAAAfS+uO8qhSpUry7bffmnF2ypcvLz/++KMZ/2fDhg3y0EMPZWuD4220UbcO9KgNorVNEwAAKBhTP/tZ5n0bKyPubChjujQTT31/56sKTAcgzDzej5bKXLhwwYy+3K1bt/wcEgAAoHhXgb322mvSpUsXUwKk83BpL7D9+/ebXlgfffRRwZ8lAACApwOQTkKq1V4675Y+a+nP4MGDpW/fvi6NogEAAEpEALp8+bI0a9ZMPv/8cxN49AEAAOBN8twGqEyZMqbaCwAAwFvlqxG0Dn6ogx7qaNAAAAC2aAO0detWM+DhF198YUaELlu2rMv7OkcXAABAiQpAFStWNOP9AAAAlPgApPNq/e1vf5N9+/ZJWlqa3H333TJ58mR6fgEAgJLbBkinnBg/fryZ7b127dry5ptvmvZAAAAAJTYAvf/++zJr1ixZtWqVLFu2TD777DP58MMPTckQAABAiQxAOjlp5qkuOnfubKbBOHHiRGGcGwAAgOcDkHZ7DwgIyDYukA6OCAAAUCIbQevE8QMHDhR/f3/nOh0Ucfjw4S5d4ekGDwAASkwAGjBgQLZ1jz76aEGeDwAAQPEKQPPnzy+8MwEAACjOU2EAAAB4MwIQAACwHQIQAACwHQIQAACwHQIQAACwHQIQAACwHQIQAACwHQIQAAAoMsmpV8zzhZSrz55CAAIAAEUiemucLN521Lz+YPMRs+wpBCAAAFDo4pMuybiYnWL9tqzP42N2mfWeQAACAACFLjYxWTIc6ec36ZYlhxMviicQgAAAQKGrH1JWSvm4rvP18ZHQkCDxBAIQAAAodDWDAyWqZ0txZCB9ntazhVnvCQQgAABQJCJvrSsPt6tjXvf7Qz2z7CkEIAAAUGTK+pc2z+UCrj57CgEIAADYDgEIAADYTrEIQDNnzpTQ0FAJCAiQsLAw2bJlS47b3nnnneLj45Ptcd999zm3GThwYLb3u3TpUkRXAwAAirvSHh8VMjpaRo8eLXPmzDHhZ8aMGRIRESF79+6VatWqZds+JiZG0tLSnMtnzpyR1q1bS69evVy208Azf/5857K/v38hXwkAAPAWHi8Bmj59ugwdOlQGDRokzZs3N0EoKChI5s2b53b7ypUrS40aNZyP1atXm+2zBiANPJm3q1SpUhFdEQAAKO48GoC0JGf79u3SuXPn/55QqVJmedOmTdd0jPfee08eeeQRKVu2rMv69evXmxKkpk2byhNPPGFKigAAADxeBZaYmCjp6elSvXp1l/W6vGfPnt/dX9sK7dq1y4SgrNVfPXv2lPr168vBgwdl/Pjx0rVrVxOqfH19sx0nNTXVPBzOnTt3XdcFAACKN4+3AboeGnxatmwp7du3d1mvJUIO+n6rVq2kYcOGplToj3/8Y7bjREVFyZQpU4rknAEAgM2rwEJCQkyJTEJCgst6XdZ2O7lJTk6WRYsWyeDBg3/35zRo0MD8rAMHDrh9f9y4cZKUlOR8HD16NI9XAgAAvIlHA5Cfn5+0bdtW1q5d61yXkZFhlsPDw3Pd9+OPPzbVVo8++ujv/pxjx46ZNkA1a9Z0+742mK5QoYLLAwAAlFwe7wWmXeDnzp0rCxculN27d5sGy1q6o73CVP/+/U0Jjbvqr+7du0uVKlVc1l+4cEGeffZZ2bx5sxw+fNiEqQcffFAaNWpkutcDAAB4vA1QZGSknD59WiZOnCgnT56UNm3ayMqVK50No+Pi4kzPsMx0jKANGzbIF198ke14WqX2n//8xwSqs2fPSq1ateTee++VF198kbGAAABA8QhAauTIkebhjjZczkq7tluW5Xb7wMBAWbVqVYGfIwAAKDk8XgUGAABQ1AhAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdghAAADAdopFAJo5c6aEhoZKQECAhIWFyZYtW3Lc9s477xQfH59sj/vuu8+5jWVZMnHiRKlZs6YEBgZK586dZf/+/UV0NQAAoLjzeACKjo6W0aNHy6RJk2THjh3SunVriYiIkFOnTrndPiYmRuLj452PXbt2ia+vr/Tq1cu5zauvvipvvvmmzJkzR7777jspW7asOWZKSkoRXhkAACiuPB6Apk+fLkOHDpVBgwZJ8+bNTWgJCgqSefPmud2+cuXKUqNGDedj9erVZntHANLSnxkzZsiECRPkwQcflFatWsn7778vJ06ckGXLlhXx1QEAgOLIowEoLS1Ntm/fbqqonCdUqpRZ3rRp0zUd47333pNHHnnElPKo2NhYOXnypMsxg4ODTdVaTsdMTU2Vc+fOuTwAAEDJ5dEAlJiYKOnp6VK9enWX9bqsIeb3aFshrQIbMmSIc51jv7wcMyoqyoQkx6NOnTr5vCIAAOANPF4Fdj209Kdly5bSvn376zrOuHHjJCkpyfk4evRogZ0jAAAofjwagEJCQkwD5oSEBJf1uqzte3KTnJwsixYtksGDB7usd+yXl2P6+/tLhQoVXB4AAKDk8mgA8vPzk7Zt28ratWud6zIyMsxyeHh4rvt+/PHHpu3Oo48+6rK+fv36JuhkPqa26dHeYL93TAAAYA+lPX0C2gV+wIAB0q5dO1OVpT24tHRHe4Wp/v37S+3atU07nazVX927d5cqVaq4rNcxgZ5++mn561//Ko0bNzaB6IUXXpBatWqZ7QEAADwegCIjI+X06dNm4EJtpNymTRtZuXKlsxFzXFyc6RmW2d69e2XDhg3yxRdfuD3mmDFjTIgaNmyYnD17Vjp27GiOqQMtAgAA+Fg6cA5caJWZ9gbTBtG0BwIAoOBM/exnmfdtrIy4s6GM6dLMY9/fXt0LDAAAID8IQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHY8HoBmzpwpoaGhEhAQIGFhYbJly5Zctz979qw8+eSTUrNmTfH395cmTZrIihUrnO9PnjxZfHx8XB7NmjUrgisBAADeorQnf3h0dLSMHj1a5syZY8LPjBkzJCIiQvbu3SvVqlXLtn1aWprcc8895r0lS5ZI7dq15ciRI1KxYkWX7W666SZZs2aNc7l0aY9eJgAAKGY8mgymT58uQ4cOlUGDBpllDULLly+XefPmydixY7Ntr+t/+eUX2bhxo5QpU8as09KjrDTw1KhRowiuAAAAeCOPVYFpac727dulc+fO/z2ZUqXM8qZNm9zu8+mnn0p4eLipAqtevbq0aNFCpk2bJunp6S7b7d+/X2rVqiUNGjSQvn37SlxcXKFfDwAA8B4eKwFKTEw0wUWDTGa6vGfPHrf7HDp0SNatW2dCjbb7OXDggIwYMUIuX74skyZNMttoVdqCBQukadOmEh8fL1OmTJFOnTrJrl27pHz58m6Pm5qaah4O586dK9BrBQAAxYtXNY7JyMgw7X/effdd8fX1lbZt28rx48flb3/7mzMAde3a1bl9q1atTCCqV6+eLF68WAYPHuz2uFFRUSYoAQAAe/BYFVhISIgJMQkJCS7rdTmn9jva80t7fel+DjfeeKOcPHnSVKm5ow2kdR8tLcrJuHHjJCkpyfk4evRovq8LAAAUfx4LQH5+fqYEZ+3atS4lPLqs7Xzc6dChgwkyup3Dvn37TDDS47lz4cIFOXjwoNkmJ9qdvkKFCi4PAABQcnl0HCDtAj937lxZuHCh7N69W5544glJTk529grr37+/KZ1x0Pe1F9hTTz1lgo/2GNNG0Noo2uGZZ56Rr776Sg4fPmx6i/Xo0cOUGPXu3dsj1wgAAIofj7YBioyMlNOnT8vEiRNNNVabNm1k5cqVzobR2ntLe4Y51KlTR1atWiWjRo0y7Xt0HCANQ88995xzm2PHjpmwc+bMGalatap07NhRNm/ebF4DAAAoH8uyLG6FK+0FFhwcbNoDUR0GAEDBmfrZzzLv21gZcWdDGdOlmce+vz0+FQYAAEBRIwABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAADbIQABAIAik5x6xTxfSLn67CkEIAAAUCSit8bJ4m1HzesPNh8xy55CAAIAAIUuPumSjIvZKdZvy/o8PmaXWe8JBCAAAFDoYhOTJcORfn6TbllyOPGieAIBCAAAFLr6IWWllI/rOl8fHwkNCRJPIAABAIBCVzM4UKJ6tjShR+nztJ4tzHpPKO2RnwoAAGwn8ta6cnuTqqbaS0t+PBV+FAEIAAAUGQ09ngw+DlSBAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA2yEAAQAA22EuMDcsyzLP586d8/SpAACAa+T43nZ8j+eGAOTG+fPnzXOdOnU8fSoAACAf3+PBwcG5buNjXUtMspmMjAw5ceKElC9fXnx8fAo8nWqwOnr0qFSoUKFAj43/4j4XDe5z0eA+Fw3us/ffZ400Gn5q1aolpUrl3sqHEiA39KbdcMMNhfoz9EPnf7DCx30uGtznosF9LhrcZ+++z79X8uNAI2gAAGA7BCAAAGA7BKAi5u/vL5MmTTLPKDzc56LBfS4a3OeiwX22132mETQAALAdSoAAAIDtEIAAAIDtEIAAAIDtEIAAAIDtEIAKwcyZMyU0NFQCAgIkLCxMtmzZkuv2H3/8sTRr1sxs37JlS1mxYkWRnatd7vPcuXOlU6dOUqlSJfPo3Lnz734uyN/vs8OiRYvMSOrdu3cv9HO0430+e/asPPnkk1KzZk3Tm6ZJkyb87SiE+zxjxgxp2rSpBAYGmtGLR40aJSkpKUV2vt7o66+/lgceeMCMxqx/A5YtW/a7+6xfv15uueUW87vcqFEjWbBgQeGfqPYCQ8FZtGiR5efnZ82bN8/66aefrKFDh1oVK1a0EhIS3G7/7bffWr6+vtarr75q/fzzz9aECROsMmXKWDt37izycy/J97lPnz7WzJkzre+//97avXu3NXDgQCs4ONg6duxYkZ97Sb7PDrGxsVbt2rWtTp06WQ8++GCRna9d7nNqaqrVrl07q1u3btaGDRvM/V6/fr31ww8/FPm5l+T7/OGHH1r+/v7mWe/xqlWrrJo1a1qjRo0q8nP3JitWrLCef/55KyYmRnuZW5988kmu2x86dMgKCgqyRo8ebb4H33rrLfO9uHLlykI9TwJQAWvfvr315JNPOpfT09OtWrVqWVFRUW63f/jhh6377rvPZV1YWJj1+OOPF/q52uk+Z3XlyhWrfPny1sKFCwvxLO15n/Xe3nbbbdY//vEPa8CAAQSgQrjPs2fPtho0aGClpaUV4Vna7z7rtnfffbfLOv2S7tChQ6Gfa0kh1xCAxowZY910000u6yIjI62IiIhCPTeqwApQWlqabN++3VSvZJ5XTJc3bdrkdh9dn3l7FRERkeP2yN99zurixYty+fJlqVy5ciGeqT3v89SpU6VatWoyePDgIjpT+93nTz/9VMLDw00VWPXq1aVFixYybdo0SU9PL8IzL/n3+bbbbjP7OKrJDh06ZKoZu3XrVmTnbQebPPQ9yGSoBSgxMdH8AdI/SJnp8p49e9zuc/LkSbfb63oU3H3O6rnnnjP101n/p8P13ecNGzbIe++9Jz/88EMRnaU977N+Ea9bt0769u1rvpAPHDggI0aMMKFeR9hFwdznPn36mP06duxoZhm/cuWKDB8+XMaPH19EZ20PJ3P4HtRZ4y9dumTaXxUGSoBgOy+//LJpoPvJJ5+YhpAoGOfPn5d+/fqZBuchISGePp0SLSMjw5Syvfvuu9K2bVuJjIyU559/XubMmePpUytRtGGulqzNmjVLduzYITExMbJ8+XJ58cUXPX1qKACUABUg/aPv6+srCQkJLut1uUaNGm730fV52R75u88Or732mglAa9askVatWhXymdrrPh88eFAOHz5sen9k/qJWpUuXlr1790rDhg2L4MxL/u+z9vwqU6aM2c/hxhtvNP+S1qoePz+/Qj9vO9znF154wYT6IUOGmGXtpZucnCzDhg0zgVOr0HD9cvoerFChQqGV/ig+vQKkf3T0X2Nr1651+QLQZa2vd0fXZ95erV69Osftkb/7rF599VXzL7eVK1dKu3btiuhs7XOfdSiHnTt3muovx+NPf/qT3HXXXea1diFGwfw+d+jQwVR7OQKm2rdvnwlGhJ+Cu8/aVjBryHGETqbRLDge+x4s1CbWNu1mqd0mFyxYYLrzDRs2zHSzPHnypHm/X79+1tixY126wZcuXdp67bXXTPfsSZMm0Q2+EO7zyy+/bLq/LlmyxIqPj3c+zp8/78GrKHn3OSt6gRXOfY6LizO9GEeOHGnt3bvX+vzzz61q1apZf/3rXz14FSXvPuvfY73PH330kemq/cUXX1gNGzY0vXeRM/27qkOO6ENjxvTp083rI0eOmPf1Huu9ztoN/tlnnzXfgzpkCd3gvZSOYVC3bl3zhavdLjdv3ux874477jBfCpktXrzYatKkidleuwIuX77cA2ddsu9zvXr1zP+IWR/6Bw4F+/ucGQGo8O7zxo0bzZAZ+oWuXeJfeuklMwQBCu4+X7582Zo8ebIJPQEBAVadOnWsESNGWL/++quHzt47fPnll27/3jrurT7rvc66T5s2bcznor/P8+fPL/Tz9NH/FG4ZEwAAQPFCGyAAAGA7BCAAAGA7BCAAAGA7BCAAAGA7BCAAAGA7BCAAAGA7BCAAAGA7BCAAuEY+Pj6ybNky81rnPdNlneYDgPchAAHwCgMHDjSBQx86EWj9+vVlzJgxkpKS4ulTA+CFmA0egNfo0qWLzJ8/Xy5fvizbt2+XAQMGmED0yiuvePrUAHgZSoAAeA1/f3+pUaOGmVm+e/fu0rlzZzNrtGNm76ioKFMyFBgYKK1bt5YlS5a47P/TTz/J/fffLxUqVJDy5ctLp06d5ODBg+a9rVu3yj333CMhISESHBwsd9xxh+zYscMj1wmg8BGAAHilXbt2ycaNG8XPz88sa/h5//33Zc6cOSbojBo1Sh599FH56quvzPvHjx+X22+/3YSodevWmRKkxx57TK5cuWLeP3/+vClR2rBhg2zevFkaN24s3bp1M+sBlDxUgQHwGp9//rmUK1fOhJbU1FQpVaqUvP322+b1tGnTZM2aNRIeHm62bdCggQkz77zzjinNmTlzpinZWbRokWlDpJo0aeI89t133+3ys959912pWLGiCVBaagSgZCEAAfAad911l8yePVuSk5Pl73//u5QuXVoeeughU+Jz8eJFU4WVWVpamtx8883mtfbW0iovR/jJKiEhQSZMmCDr16+XU6dOSXp6ujlmXFxckVwbgKJFAALgNcqWLSuNGjUyr+fNm2fa+bz33nvSokULs2758uVSu3Ztl320yktpu6DcaPXXmTNn5I033pB69eqZ/bQ0SUMUgJKHAATAK2n11/jx42X06NGyb98+E1i0tEaru9xp1aqVLFy40PQgc1cK9O2338qsWbNMux919OhRSUxMLPTrAOAZNIIG4LV69eolvr6+pp3PM888Yxo+a8jRnl3ag+utt94yy2rkyJFy7tw5eeSRR2Tbtm2yf/9++eCDD2Tv3r3mfW30rMu7d++W7777Tvr27fu7pUYAvBclQAC8lrYB0mDz6quvSmxsrFStWtX0Bjt06JBpwHzLLbeYUiJVpUoV0/vr2WefNaVEGpzatGkjHTp0MO9rVdqwYcPMPtrNXhtVa6gCUDL5WJZlefokAAAAihJVYAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHYIQAAAwHb+H5VlCB40clymAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Get precision and recall values\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df4933",
   "metadata": {},
   "source": [
    "# 24. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12635b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a stacking classifier\n",
    "estimators = [\n",
    "    ('dt', DecisionTreeClassifier()),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=1000))\n",
    "stacking_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate stacking classifier\n",
    "y_pred = stacking_clf.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ca68a",
   "metadata": {},
   "source": [
    "# 25. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a5e326f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier (RF + LR) Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load breast cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "X, y = cancer.data, cancer.target\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a stacking classifier with Random Forest and Logistic Regression\n",
    "stacking_rf_lr = StackingClassifier(estimators=[\n",
    "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "], final_estimator=LogisticRegression(max_iter=1000))\n",
    "\n",
    "stacking_rf_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate stacking classifier\n",
    "y_pred = stacking_rf_lr.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Stacking Classifier (RF + LR) Accuracy: {accuracy:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
